# ai_processor.py
import logging
import re
from typing import List, Dict
import config

logger = logging.getLogger(__name__)

class AIProcessor:
    def __init__(self):
        self.keywords = {
            '–∞–∫—Ü–∏–∏': ['—Å–∫–∏–¥–∫', '—Ä–∞—Å–ø—Ä–æ–¥–∞–∂', '–∞–∫—Ü–∏', '–±–æ–Ω—É—Å', '–ø—Ä–æ–º–æ–∫–æ–¥', '%'],
            '–Ω–æ–≤–æ—Å—Ç–∏': ['–∑–∞–ø—É—Å–∫', '–æ–±–Ω–æ–≤–ª–µ–Ω', '–Ω–æ–≤—ã–π', '–∞–Ω–æ–Ω—Å', '—Ä–µ–ª–∏–∑'],
            '–¥–æ—Å—Ç–∞–≤–∫–∞': ['–¥–æ—Å—Ç–∞–≤–∫', '–æ—Ç–ø—Ä–∞–≤–∫', '–ø–æ–ª—É—á–µ–Ω', '–∫—É—Ä—å–µ—Ä', '–ø—É–Ω–∫—Ç –≤—ã–¥–∞—á–∏'],
            '–º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å': ['ozon', 'wildberries', '—è–Ω–¥–µ–∫—Å –º–∞—Ä–∫–µ—Ç']
        }
    
    def clean_text(self, text: str) -> str:
        text = re.sub(r'http\S+', '', text)
        text = re.sub(r'[^\w\s\.\!\?,:;-–∞-—è–ê-–Ø]', '', text)
        text = re.sub(r'\s+', ' ', text)
        return text.strip()
    
    def detect_marketplace(self, text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
        text_lower = text.lower()
        
        for marketplace, keywords in config.MARKETPLACE_KEYWORDS.items():
            if any(keyword in text_lower for keyword in keywords):
                return marketplace
        
        return 'other'
    
    def group_by_marketplace(self, messages: List[Dict]) -> Dict[str, List[str]]:
        """–ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞–º"""
        grouped = {'OZON': [], 'WB': [], 'other': []}
        
        for msg in messages:
            if isinstance(msg, dict):
                text = msg['text']
                marketplace = msg.get('marketplace', self.detect_marketplace(text))
            else:
                text = msg
                marketplace = self.detect_marketplace(text)
            
            grouped[marketplace].append(text)
        
        return grouped
    
    def summarize_text(self, text: str) -> str:
        clean_text = self.clean_text(text)
        sentences = re.split(r'[.!?]+', clean_text)
        sentences = [s.strip() for s in sentences if len(s.strip()) > 10]
        
        if len(sentences) <= 2:
            return clean_text
        
        important_sentences = []
        if sentences:
            important_sentences.append(sentences[0])
        
        key_phrases = ['–Ω–æ–≤—ã–π', '–∑–∞–ø—É—Å–∫', '—Å–∫–∏–¥–∫', '–∞–∫—Ü–∏', '–≤–∞–∂–Ω–æ']
        for sentence in sentences[1:]:
            if any(phrase in sentence.lower() for phrase in key_phrases):
                if sentence not in important_sentences:
                    important_sentences.append(sentence)
                    if len(important_sentences) >= 2:
                        break
        
        if len(important_sentences) < 2 and len(sentences) > 1:
            important_sentences.append(sentences[-1])
        
        result = '. '.join(important_sentences[:2])
        return result if len(result) > 20 else clean_text[:200] + "..."
    
    def analyze_sentiment(self, text: str) -> str:
        positive = ['–æ—Ç–ª–∏—á–Ω', '—Ö–æ—Ä–æ—à', '—É—Å–ø–µ—Ö', '–ø—Ä–µ–∫—Ä–∞—Å–Ω', '—Ä–µ–∫–æ–º–µ–Ω–¥', '–¥–æ–≤–æ–ª–µ–Ω', '—Å—É–ø–µ—Ä']
        negative = ['–ø—Ä–æ–±–ª–µ–º', '–æ—à–∏–±–∫', '–ø–ª–æ—Ö', '—Å–ª–æ–∂–Ω', '–Ω–µ—É–¥–æ–±–Ω', '—É–∂–∞—Å–Ω']
        
        text_lower = text.lower()
        pos = sum(1 for word in positive if word in text_lower)
        neg = sum(1 for word in negative if word in text_lower)
        
        if pos > neg:
            return '–ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π'
        elif neg > pos:
            return '–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π'
        else:
            return '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π'
    
    def extract_topic(self, text: str) -> str:
        text_lower = text.lower()
        for topic, keywords in self.keywords.items():
            if any(keyword in text_lower for keyword in keywords):
                return topic
        return '–Ω–æ–≤–æ—Å—Ç–∏'
    
    def structure_content_by_marketplace(self, main_posts: List[Dict], discussion_posts: List[Dict]) -> Dict:
        """–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞–º"""
        logger.info("üß† –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞–º...")
        
        try:
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞–º
            main_grouped = self.group_by_marketplace(main_posts)
            discussion_grouped = self.group_by_marketplace(discussion_posts)
            
            structured_content = {}
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å –æ—Ç–¥–µ–ª—å–Ω–æ
            for marketplace in ['OZON', 'WB']:
                marketplace_main = main_grouped[marketplace]
                marketplace_discussion = discussion_grouped[marketplace]
                
                if not marketplace_main:
                    continue
                
                main_summaries = []
                main_topics = set()
                
                for post in marketplace_main[:3]:
                    if len(post.strip()) > 20:
                        summary = self.summarize_text(post)
                        topic = self.extract_topic(post)
                        main_summaries.append(summary)
                        main_topics.add(topic)
                
                discussion_insights = []
                for post in marketplace_discussion[:5]:
                    if len(post.strip()) > 20:
                        sentiment = self.analyze_sentiment(post)
                        summary = self.summarize_text(post)
                        discussion_insights.append({
                            'text': summary,
                            'sentiment': sentiment
                        })
                        if len(discussion_insights) >= 2:
                            break
                
                structured_content[marketplace] = {
                    'main_topic': ' | '.join(list(main_topics)[:2]) if main_topics else '–Ω–æ–≤–æ—Å—Ç–∏',
                    'main_content': main_summaries,
                    'discussion_insights': discussion_insights,
                    'has_ai_analysis': len(main_summaries) > 0,
                    'message_count': len(marketplace_main)
                }
            
            return structured_content
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            return {}